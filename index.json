











































































[{"categories":null,"contents":"These days, our online presence leaves traces of our behavior everywhere. There is data of what we do and say in platforms such as WhatsApp, Instagram, online stores, and many others. Of course, this so-called ‚Äòdigital trace data‚Äô is of interest for social scientists: new, rich, enormous datasets that can be used to describe and understand our social world. However, this data is commonly owned by private companies. How can social scientists access and make sense of this data?\nIn this tutorial, we use data donation and the Port software to get access to WhatsApp group-chat data in a way that completely preserves privacy of research participants. Our goal is to show a small peek of what can be achieved with these methods. If you have an idea for your own research that entails collecting digital trace data, don‚Äôt hesitate to contact us! We can help you think about data acquisition, analysis and more.\nWith data donation, it is possible to collect data about any online platform: under the General Data Protection Regulation (EU law), companies are required to provide their data to any citizen that requests it. This data is available in so-called Data Download Packages (DDP‚Äôs), which are rather cumbersome to work with and contain personal information. Therefore, the Port software processes these DDP‚Äôs so that the data is in a format ready for analysis, while completely guaranteeing privacy of the respondents. The only thing research participants have to do is request their DDP‚Äôs, see which information they are sharing and consent to sharing it.\nSince we do not dive in with a lot of detail, we refer to Port\u0026rsquo;s github for more details on how to get started with your own project. There you can find a full guide to install and use Port, examples of past studies done with it, a tutorial for creating your own data donation workflow, and more. You can also read more about data donation in general here and here.\nAn application with WhatsApp data In this example, we extract some basic information from WhatsApp group chats, such as how many messages links, locations, and pictures were shared, as well as which person in the group the participant responded most to.\nNote that this is the only information we want to collect from the participants of the study, not the whole group chat file!\nThe first step in creating a DDP processing script is to obtain an example DDP and examine it. This example DDP can be, for example, your own DDP requested from WhatsApp. Usually, platforms provide a (compressed) folder with many different files; i.e., data in a format that is not ready to use. Once uncompressed, a WhatsApp group chat file could look like this:\n[16/03/2022, 15:10:17] Messages and calls are end-to-end encrypted. No one outside of this chat, not even WhatsApp, can read or listen to them. Tap to learn more. [16/03/2022, 15:20:25] person1: Hi shiva! [16/03/2022, 15:25:38] person2: Hi üëã [16/03/2022, 15:26:48] person3: Hoi! [16/03/2022, 18:39:29] person2: https://youtu.be/KBmUTY6mK_E [16/03/2022, 18:35:51] person1: ‚ÄéLocation: https://maps.google.com/?q=52.089451,5.108469 [20/03/2022, 20:08:51] person4: I‚Äôm about to generate some very random messages so that I can make some screenshots for the explanation to participants [24/03/2022, 20:19:38] person1: @user3 if you remove your Profile picture for a moment I will redo the screenshots üòÅ [26/03/2022, 18:52:15] person2: Well done Utrecht üòÅ [14/07/2020, 22:05:54] person4: üëçBedankt As part of a collaboration with data donation researchers using Port, we wrote a Python script1 to convert this into the information we need. The main script is available here; in short, it does the following:\nseparate the header and the message itself parse the date and time information in each message remove unneeded information such as alert notifications anonymize usernames convert the extracted information to a nice data frame format to show the participant for consent One big problem we had to overcome is that messages and alert notifications cannot be identified in the same way (i.e., using the same regular expression) on every device. Through trial-and-error, we tailored the steps to work with every operating system, language, and device required for this study. Indeed, if you design a study like this, it is very important to try out your script on many different DDPs from different people and devices. That way you will make sure you have covered possible variation in DPPs before actually starting data collection. This is a process that can take quite a while, so keep this in mind when you want to run a data donation study!\nThe end result In Figure 1 you can see a (fictitious) snippet of the dataset obtained. This is how a dataset in which you combine donations from different users would look like. As can be seen, we have moved from a rather untidy text file to a tidy, directly analysable dataset, where each row corresponds to an user in a given data donation package, and the rest of the columns give information about that user. Particularly, the dataset displays the following information: data donation package id (ddp_id), an anonymized user name (user_name), number of words sent on the groupchat by the user (nwords), date of first and last messages sent on the groupchat by the user (date_first_mess, date_last_mess), number of urls, files and locations sent on the groupchat by the user (respectively, nurls, nfiles, nlocations), and the (other) user that has replied more to that user (replies_from), as well as the user that that user has replied to the most (replies_to).\nTable 1. Snippet of fictitious dataset\nddp_id user_name nwords date_first_mess date_last_mess nurls nfiles nlocations replies_from replies_to 1 User1_1 121 10/08/2023 27/08/2023 0 15 0 User1_2 User1_4 1 User1_2 17 11/08/2023 28/08/2023 3 1 2 User1_1 User1_1 1 User1_3 44 10/08/2023 28/08/2023 9 6 3 User1_2 User1_1 1 User1_4 50 12/08/2023 29/08/2023 0 3 1 User1_3 User1_1 2 User2_1 123 01/05/2022 01/11/2022 2 0 1 User2_2 User2_2 2 User2_2 250 01/05/2022 02/11/2022 0 32 3 User2_3 User2_1 2 User2_3 176 08/07/2022 04/12/2022 6 0 5 User2_2 User2_3 3 User3_1 12 05/06/2023 26/07/2023 12 2 0 User3_1 User3_2 3 User3_2 16 06/06/2023 26/07/2023 17 2 0 User3_2 User3_1 In Figure 2 you can see a screenshot of how the Port software would display the data to be shared (number of words or messages, date stamps‚Ä¶) and ask for consent to the research subjects. As you see, the Port software guarantees that research subjects are aware of what information they are sharing and consent to it. The rest of the DDPs, including sensitive data, is analyzed locally and does not leave the respondents\u0026rsquo; devices.\nFigure 2. How the Port software displays the data to be shared and asks for consent\rConclusion The aim of this post was to illustrate how to use data donation with the software Port to extract online platform data. We illustrated all of this with the extraction of group-chat information from WhatsApp data. The main challenge of this project was to write a robust script that transforms this data into a nice, readily usable format while maintaining privacy. If you want to implement something similar but do not know how or where to start, let us know and we can help!\nThis script uses a deprecated version of Port, but large part of the script can be reused;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"September 8, 2023","image":"http://odissei-soda.nl/images/tutorial-4/whatsapp_header_hu3d03a01dcc18bc5be0e67db3d8d209a6_1708177_650x0_resize_q100_box.jpg","permalink":"/tutorials/post-4/","title":"Collecting online platforms data for science: an example using WhatsApp"},{"categories":null,"contents":"ArtScraper is a Python library to download images and metadata for artworks available on WikiArt and Google Arts \u0026amp; Culture.\nInstallation pip install https://github.com/sodascience/artscraper.git Downloading images from WikiArt To download data from WikiArt it is necessary to obtain free API keys.\nOnce you have the API keys, you can simply run the code below to download the images and metadata of the three artworks of Aleksandra Ekster.\n# artworks to scrape some_links = [ \u0026#34;https://www.wikiart.org/en/aleksandra-ekster/women-s-costume-1918\u0026#34;, \u0026#34;https://www.wikiart.org/en/aleksandra-ekster/still-life-1913\u0026#34;, \u0026#34;https://www.wikiart.org/en/aleksandra-ekster/view-of-paris-1912\u0026#34; ] # download images and metadata to the folder \u0026#34;data\u0026#34; with WikiArtScraper(output_dir=\u0026#34;data\u0026#34;) as scraper: for url in some_links: scraper.load_link(url) scraper.save_metadata() scraper.save_image() Downloading images from Google Art \u0026amp; Culture To download data from Google Art \u0026amp; Culture you need to download Firefox and geckodriver. The installation instructions can be found in our GitHub repository.\nOnce you have Firefox and geckodriver, you can simply run the code below to download artworks. You are not allowed to share or publish the images. Use them only for research.\n# artworks to scrape some_links = [ \u0026#34;https://artsandculture.google.com/asset/helena-hunter-fairytales/dwFMypq0ZSiq6w\u0026#34;, \u0026#34;https://artsandculture.google.com/asset/erina-takahashi-and-isaac-hernandez-in-fantastic-beings-laurent-liotardo/MQEhgoWpWJUd_w\u0026#34;, \u0026#34;https://artsandculture.google.com/asset/rinaldo-roberto-masotti/swG7r2rgfvPOFQ\u0026#34; ] # If you are on Windows, you can download geckodriver, place it in your directory, # and use the argument geckodriver_path=\u0026#34;geckodriver.exe\u0026#34; with GoogleArtScraper(\u0026#34;data\u0026#34;) as scraper: for url in some_links: scraper.load_link(url) scraper.save_metadata() scraper.save_image() You can find more examples here\nDo you want to know more about this library? Check our GitHub repository\nAre you using it for academic work? Please cite our package:\nSchram, Raoul, Garcia-Bernardo, Javier, van Kesteren, Erik-Jan, de Bruin, Jonathan, \u0026amp; Stamkou, Eftychia. (2022). ArtScraper: A Python library to scrape online artworks (0.1.1). Zenodo. https://doi.org/10.5281/zenodo.7129975 ","date":"October 4, 2022","image":"http://odissei-soda.nl/images/tutorial-2/nantenbo_header_hu48d98726654ff846597d2fe25a58192f_52421_650x0_resize_q100_box.jpg","permalink":"/tutorials/post-2/","title":"ArtScraper: A Python library to scrape online artworks"},{"categories":null,"contents":"With the increasing popularity of open science practices, it is now more and more common to openly share code along with more traditional scientific objects such as papers. But what are the best ways to create an understandable, openly accessible, findable, citable, and stable archive of your code? In this post, we look at what you need to do to prepare your code folder and then how to upload it to Zenodo.\nPrepare your code folder To make code available, you will be uploading it to the internet as a single folder. The code you will upload will be openly accessible, and it will stay that way indefinitely. Therefore, it is necessary that you prepare your code folder (also called a ‚Äúrepository‚Äù) for publication. This requires time and effort, and for every project the requirements are different. Think about the following checklist:\nMust-haves Make a logical, understandable folder structure. For example, for a research project with data processing, visualization, and analysis I like the following structure: my_project/\u0026lt;br/\u0026gt; ‚îú‚îÄ raw_data/\u0026lt;br/\u0026gt; ‚îÇ ‚îú‚îÄ questionnaire_data.csv\u0026lt;br/\u0026gt; ‚îú‚îÄ processed_data/\u0026lt;br/\u0026gt; ‚îÇ ‚îú‚îÄ questionnaire_processed.rds\u0026lt;br/\u0026gt; ‚îÇ ‚îú‚îÄ analysis_object.rds\u0026lt;br/\u0026gt; ‚îú‚îÄ img/\u0026lt;br/\u0026gt; ‚îÇ ‚îú‚îÄ plot.png\u0026lt;br/\u0026gt; ‚îú‚îÄ 01_load_and_process_data.R\u0026lt;br/\u0026gt; ‚îú‚îÄ 02_create_visualisations.R\u0026lt;br/\u0026gt; ‚îú‚îÄ 03_main_analysis.R\u0026lt;br/\u0026gt; ‚îú‚îÄ 04_output_results.R\u0026lt;br/\u0026gt; ‚îú‚îÄ my_project.Rproj\u0026lt;br/\u0026gt; ‚îú‚îÄ readme.md Make sure no privacy-sensitive information is leaked. Remove non-shareable data objects (raw and processed!), passwords hardcoded in your scripts, comments containing private information, and so on. Create a legible readme file in the folder that describes what the code does, where to find which parts of the code, and what needs to be done to run the code. You can choose how elaborate to make this! It could be a simple text file, a word document, a pdf, or a markdown document with images describing the structure. It is best if someone who does not know the project can understand the entire folder based on the readme ‚Äì this includes yourself in a few years from now! Strong recommendations Reformat the code so that it is portable and easily reproducible. This means that when someone else downloads the folder, they do not need to change the code to run it. For example this means that you do not read data with absolute paths (e.g., C:/my_name/Documents/PhD/projects/project_title/raw_data/questionnaire_data.csv) on your computer, but only to relative paths on the project (e.g., raw_data/questionnaire_data.csv). For example, if you use the R programming language it is good practice to use an RStudio project. Format your code so that it is legible by others. Write informative comments, split up your scripts in logical chunks, and use a consistent style (for R I like the tidyverse style) Nice to have Record the software packages that you used to run the projects, including their versions. If a package gets updated, your code may no longer run! Your package manager may already do this, e.g., for python you can use pip freeze \u0026gt; requirements.txt. In R, you can use the renv package for this. If you have privacy-sensitive data, it may still be possible to create a synthetic or fake version of this data for others to run the code on. This ensures maximum reproducibility. Compressing the code folder The last step before uploading the code repository to Zenodo is to compress the folder. This can be done in Windows 11 by right-clicking the folder and pressing ‚Äúcompress to zip file‚Äù. It‚Äôs a good idea to go into the compressed folder afterwards, and checking if everything is there and also removing any unnecessary files (such as .Rhistory files for R).\nFigure 1: Zipping the code folder.\rAfter compressing, your code repository is now ready to be uploaded!\nUploading to Zenodo Zenodo is a website where you can upload any kind of research object: papers, code, datasets, questionnaires, presentations, and much more. After uploading, Zenodo will create a page containing your research object and metadata about the object, such as publication date, author, and keywords. In the figure below you can see an example of a code repository uploaded to Zenodo.\nFigure 2: A code repository uploaded to the Zenodo website. See https://zenodo.org/record/6504837\rOne of the key features of Zenodo is that you can get a Digital Object Identifier (DOI) for the objects you upload, making your research objects persistent and easy to find and cite. For example, in APA style I could cite the code as follows:\nvan Kesteren, Erik-Jan. (2022). My project (v1.2). Zenodo. https://doi.org/10.5281/zenodo.6504837\nZenodo itself is fully open source, hosted by CERN, and funded by the European Commission. These are exactly the kinds of conditions which make it likely to last for a long time! Hence, it is an excellent choice for uploading our code. So let‚Äôs get started!\nCreate an account To upload anything to Zenodo, you need an account. If you already have an ORCID or a GitHub account, then you can link these immediately to your Zenodo login. I do recommend doing so as it will make it easy to link these services and use them together.\nFigure 3: Zenodo sign-up page. See https://zenodo.org/signup/\rStart a new upload When you click the ‚Äúupload‚Äù button, you will get a page where you can upload your files, determine the type of the upload, and create metadata for the research object. Now zip your prepared code folder and drag it to the upload window!\nFigure 4: Uploading a zipped folder to the Zenodo website.\rFill out the metadata One of the first options you need to specify is the ‚Äúupload type‚Äù. For code repositories, you can choose the ‚Äúsoftware‚Äù option. The remaining metadata is relatively simple to fill out (such as author and institution). However, one category to pay attention to is the license: by default the CC-BY-4.0 license is selected. For a short overview of what this means, see the creative commons website: https://creativecommons.org/licenses/by/4.0/. You can opt for a different license by including a file called LICENSE in your repository.\nFigure 5: Selecting the \u0026lsquo;software\u0026rsquo; option for upload type.\rPublish! The last step is to click ‚Äúpublish‚Äù. Your research code is now findable, citable, understandable, reproducible, and archived until the end of times! You can now show it to all your colleagues and easily cite it in your manuscript. If you get feedback and you want to change your code, you can also upload a new version of the same project on the Zenodo website.\nConclusion In this post, I described a checklist for preparing your code folder for publication with a focus on understandability, and I have described one way in which you can upload your prepared code repository to an open access archive. Zenodo is an easy, dependable and well-built option, but of course there are many alternatives, such as hosting it on your own website, using the Open Science Framework, GitHub, or using a publisher‚Äôs website; each has its own advantages and disadvantages.\n","date":"September 5, 2022","image":"http://odissei-soda.nl/images/tutorial-1/tutorial1_header_hu650f89d19acf6379f59d4eaf3a39c00b_29682_650x0_resize_box_3.png","permalink":"/tutorials/post-1/","title":"How to share your research code"},{"categories":null,"contents":"During your time as a fellow:\nyou will spend between 3-8 months full-time* working on a social science research project. you can propose your own project, based on your interests. you are a member of the SoDa team at the Methodology \u0026amp; Statistics department of Utrecht University. you will get a salary during this time, paid for by the team. one of the senior team members will be your mentor. To apply, you have to submit a short proposal for your project, together with a substantive supervisor. We are looking for projects in the social sciences for which a computational or data-related problem needs to be solved.\nThe next submission deadline is 31 September 2023\n* part-time possible, but the project should be your main priority.\n","date":"January 1, 1","image":"http://odissei-soda.nl/images/tutorial-1/tutorial1_header_hu650f89d19acf6379f59d4eaf3a39c00b_29682_650x0_resize_box_3.png","permalink":"/fellowship/","title":"Fellowship"},{"categories":null,"contents":"","date":"January 1, 1","image":"http://odissei-soda.nl/images/tutorial-1/tutorial1_header_hu650f89d19acf6379f59d4eaf3a39c00b_29682_650x0_resize_box_3.png","permalink":"/principles/","title":"Principles"},{"categories":null,"contents":"","date":"January 1, 1","image":"http://odissei-soda.nl/images/tutorial-1/tutorial1_header_hu650f89d19acf6379f59d4eaf3a39c00b_29682_650x0_resize_box_3.png","permalink":"/projects/","title":"Projects"},{"categories":null,"contents":"","date":"January 1, 1","image":"http://odissei-soda.nl/images/tutorial-1/tutorial1_header_hu650f89d19acf6379f59d4eaf3a39c00b_29682_650x0_resize_box_3.png","permalink":"/team/","title":"The SoDa Team"}]